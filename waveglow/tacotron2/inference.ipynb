{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "# from denoiser import Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                       interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_dim: 128\n",
      "attention_location_kernel_size: 31\n",
      "attention_location_n_filters: 32\n",
      "attention_rnn_dim: 1024\n",
      "batch_size: 16\n",
      "cudnn_benchmark: false\n",
      "cudnn_enabled: true\n",
      "decoder_rnn_dim: 1024\n",
      "dist_backend: nccl\n",
      "dist_url: tcp://localhost:54321\n",
      "distributed_run: false\n",
      "dynamic_loss_scaling: true\n",
      "encoder_embedding_dim: 512\n",
      "encoder_kernel_size: 5\n",
      "encoder_n_convolutions: 3\n",
      "epochs: 37\n",
      "filter_length: 1024\n",
      "fp16_run: false\n",
      "gate_threshold: 0.5\n",
      "grad_clip_thresh: 1.0\n",
      "hop_length: 256\n",
      "ignore_layers:\n",
      "- embedding.weight\n",
      "iters_per_checkpoint: 200\n",
      "learning_rate: 0.001\n",
      "load_mel_from_disk: false\n",
      "mask_padding: true\n",
      "max_decoder_steps: 1000\n",
      "max_wav_value: 32768.0\n",
      "mel_fmax: 8000.0\n",
      "mel_fmin: 0.0\n",
      "n_frames_per_step: 1\n",
      "n_mel_channels: 80\n",
      "n_symbols: 150\n",
      "p_attention_dropout: 0.1\n",
      "p_decoder_dropout: 0.1\n",
      "postnet_embedding_dim: 512\n",
      "postnet_kernel_size: 5\n",
      "postnet_n_convolutions: 5\n",
      "prenet_dim: 256\n",
      "sampling_rate: 22050\n",
      "seed: 1234\n",
      "symbols_embedding_dim: 512\n",
      "text_cleaners:\n",
      "- flowtron_cleaners\n",
      "training_files: filelists/vlsp/train.txt\n",
      "use_saved_learning_rate: false\n",
      "validation_files: filelists/vlsp/test.txt\n",
      "weight_decay: 1.0e-06\n",
      "win_length: 1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/checkpoint_10400\"\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "_ = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load WaveGlow for mel2audio synthesis and denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveglow_path = 'waveglow_256channels.pt'\n",
    "# waveglow = torch.load(waveglow_path)['model']\n",
    "# waveglow.cuda().eval().half()\n",
    "# for k in waveglow.convinv:\n",
    "#     k.float()\n",
    "# denoiser = Denoiser(waveglow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"nếu bây giờ mà phá một chiếc cầu trong vụ này . chúng nó sẽ lùng chúng tôi\"\n",
    "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).cuda().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import layers\n",
    "from utils import load_wav_to_torch, load_filepaths_and_text\n",
    "from text import text_to_sequence\n",
    "from text import _clean_text, get_arpabet\n",
    "from text import cmudict\n",
    "import re\n",
    "from text import text_embedding\n",
    "text = \"nếu bây giờ mà phá một chiếc cầu trong vụ này . chúng nó sẽ lùng chúng tôi\"\n",
    "text = _clean_text(text, hparams.text_cleaners)\n",
    "words = re.findall(r'\\S*\\{.*?\\}\\S*|\\S+', text)\n",
    "\n",
    "cmudictx = cmudict.CMUDict(\n",
    "            './text/phone_vn_north.txt',\n",
    "            keep_ambiguous=True\n",
    "        )\n",
    "\n",
    "text = ' '.join([get_arpabet(word,cmudictx)\n",
    "                 if random.random() < 0.5 \n",
    "                 else word\n",
    "                 for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_norm =self.text_embedding.text_norm(text)# text_embedding.text_norm(text)\n",
    "# text_out =self.text_embedding.g2s_model(text_norm)  #text_embedding.g2s(text_norm)\n",
    "# print(text_norm)\n",
    "sequence = self.text_embedding.text2seq(text_norm)\n",
    "# text_norm = torch.IntTensor(text_to_sequence(text, self.text_cleaners))\n",
    "text_norm = torch.LongTensor(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import TextMelLoader, TextMelCollate\n",
    "trainset = TextMelLoader(hparams.training_files, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 76])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=trainset.get_text(\n",
    "    text\n",
    ")\n",
    "sequence = torch.autograd.Variable(\n",
    "    inputs.unsqueeze(0)).cuda().long()\n",
    "sequence.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4770e-04, 6.4898e-04, 5.8556e-03,  ..., 1.1330e-02,\n",
       "          9.2850e-03, 4.3831e-03],\n",
       "         [9.1016e-05, 2.8467e-04, 6.2561e-03,  ..., 1.1826e-02,\n",
       "          8.8882e-03, 3.7365e-03],\n",
       "         [5.6922e-05, 2.3782e-04, 8.5144e-03,  ..., 8.7204e-03,\n",
       "          6.1111e-03, 2.7866e-03],\n",
       "         ...,\n",
       "         [1.5557e-05, 2.7955e-05, 1.7405e-04,  ..., 2.8920e-04,\n",
       "          1.9717e-04, 1.4424e-04],\n",
       "         [1.4424e-05, 2.6464e-05, 1.7953e-04,  ..., 2.5725e-04,\n",
       "          1.7536e-04, 1.2636e-04],\n",
       "         [1.4961e-05, 2.6464e-05, 1.8096e-04,  ..., 2.7156e-04,\n",
       "          1.8668e-04, 1.3137e-04]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_re =torch.exp(mel_outputs_postnet)\n",
    "mel_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 386])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_re.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array type float16 is unsupported in linalg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-51dab1388606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m S = librosa.feature.inverse.mel_to_stft(mel_re.squeeze(0).detach().cpu().numpy(),\n\u001b[0m\u001b[1;32m      3\u001b[0m                                         n_fft = 1024)\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                                         hop_length=25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/librosa/feature/inverse.py\u001b[0m in \u001b[0;36mmel_to_stft\u001b[0;34m(M, sr, n_fft, power, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# the inverse exponent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# We'll do the exponentiation in-place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0minverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/librosa/util/_nnls.py\u001b[0m in \u001b[0;36mnnls\u001b[0;34m(A, B, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nnls_lbfgs_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mx_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Incompatible dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2276\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2277\u001b[0m     \u001b[0;31m# FIXME: real_t is unused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[0mreal_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_linalgRealType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_commonType\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# unsupported inexact scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 raise TypeError(\"array type %s is unsupported in linalg\" %\n\u001b[0m\u001b[1;32m    147\u001b[0m                         (a.dtype.name,))\n\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: array type float16 is unsupported in linalg"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "S = librosa.feature.inverse.mel_to_stft(mel_re.squeeze(0).detach().cpu().numpy(),\n",
    "                                        n_fft = 1024)\n",
    "#                                         hop_length=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_processing import griffin_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [1026, 1, 1024], but got 2-dimensional input of size [80, 772] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e4d8ca95b84c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgriffin_lim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/speech/tacotron2/tacotron2/audio_processing.py\u001b[0m in \u001b[0;36mgriffin_lim\u001b[0;34m(magnitudes, stft_fn, n_iters)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mangles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mangles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstft_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagnitudes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/speech/tacotron2/tacotron2/stft.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, magnitude, phase)\u001b[0m\n\u001b[1;32m    109\u001b[0m             [magnitude*torch.cos(phase), magnitude*torch.sin(phase)], dim=1)\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         inverse_transform = F.conv_transpose1d(\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mrecombine_magnitude_phase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [1026, 1, 1024], but got 2-dimensional input of size [80, 772] instead"
     ]
    }
   ],
   "source": [
    "wavs = griffin_lim(mel_re.squeeze(0).detach().cpu(), trainset.stft.stft_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthesize audio from spectrogram using WaveGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Remove WaveGlow bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_denoised = denoiser(audio, strength=0.01)[:, 0]\n",
    "ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
